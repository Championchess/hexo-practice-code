{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:24:56.347420Z",
     "start_time": "2018-10-16T07:24:56.027460Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:24:56.353147Z",
     "start_time": "2018-10-16T07:24:56.350087Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:24:56.414342Z",
     "start_time": "2018-10-16T07:24:56.356394Z"
    }
   },
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    def __init__(self):\n",
    "        self.is_leaf = False\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.split_feature = None\n",
    "        self.split_value = None\n",
    "        self.child_weight = None\n",
    "\n",
    "    def calc_gain(self, G_l, G_r, H_l, H_r, lambd, gamma):\n",
    "        \"\"\"Measure how good a tree is. Equation 7\"\"\"\n",
    "        def calc_term(g, h):\n",
    "            return np.square(g) / (h + lambd)\n",
    "        gain = 0.5 * (calc_term(G_l, H_l) + \\\n",
    "                      calc_term(G_r, H_r) - \\\n",
    "                      calc_term(G_l + G_r, H_l + H_r)) - gamma\n",
    "        # the bigger gamma, the more convative\n",
    "        return gain\n",
    "    \n",
    "    def calc_child_weight(self, g, h, lambd):\n",
    "        \"\"\"Calc the optimal weight of leaf node. Equation 5\"\"\"\n",
    "        return - np.sum(g) / (np.sum(h) + lambd)\n",
    "    \n",
    "    def build(self, instances, grad, hessian, eta, depth, param):\n",
    "        \"\"\"Algorithm 1\"\"\"\n",
    "        if depth > param['max_depth']:\n",
    "            # If the depth now is bigger than max depth, it is leaf node, and stop growing.\n",
    "            self.is_leaf = True\n",
    "            self.weight = self.calc_child_weight(grad, hessian, param['lambda']) * eta\n",
    "            return\n",
    "        G = np.sum(grad)\n",
    "        H = np.sum(hessian)\n",
    "        best_gain = 0.\n",
    "        best_feature = None\n",
    "        best_val = 0.\n",
    "        best_left_instances = None\n",
    "        best_right_instances = None\n",
    "        for feature in range(instances.shape[1]):\n",
    "            G_l, H_l = 0., 0.\n",
    "            sorted_instances = instances[:, feature].argsort()\n",
    "            for j in range(len(sorted_instances)):\n",
    "                G_l += grad[sorted_instances[j]]\n",
    "                H_l += hessian[sorted_instances[j]]\n",
    "                G_r = G - G_l\n",
    "                H_r = H - H_l\n",
    "                current_gain = self.calc_gain(G_l, H_l, G_r, H_r,\n",
    "                                              param['lambda'], param['gamma'])\n",
    "                if current_gain > best_gain:\n",
    "                    best_gain = current_gain\n",
    "                    best_feature = feature\n",
    "                    best_val = instances[sorted_instances[j]][feature]\n",
    "                    best_left_instances = sorted_instances[:j+1]\n",
    "                    best_right_instances = sorted_instances[j+1:]\n",
    "        if best_gain < param['min_split_gain']:\n",
    "            self.is_leaf = True\n",
    "            self.weight = self.calc_child_weight(grad, hessian, param['lambda']) * eta\n",
    "        else:\n",
    "            self.split_feature = best_feature\n",
    "            self.split_value = best_val\n",
    "            self.left_child = TreeNode()\n",
    "            self.left_child.build(instances[best_left_instances],\n",
    "                                  grad[best_left_instances],\n",
    "                                  hessian[best_left_instances],\n",
    "                                  eta, depth+1, param)\n",
    "            \n",
    "            self.right_child = TreeNode()\n",
    "            self.right_child.build(instances[best_right_instances],\n",
    "                                  grad[best_right_instances],\n",
    "                                  hessian[best_right_instances],\n",
    "                                  eta, depth+1, param)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.weight\n",
    "        else:\n",
    "            if x[self.split_feature] <= self.split_value:\n",
    "                return self.left_child.predict(x)\n",
    "            else:\n",
    "                return self.right_child.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:24:56.490099Z",
     "start_time": "2018-10-16T07:24:56.416836Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    \"\"\"Tree ensemble\"\"\"\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "    \n",
    "    def build(self, instances, grad, hessian, eta, param):\n",
    "        self.root = TreeNode()\n",
    "        current_depth = 0\n",
    "        self.root.build(instances, grad, hessian, eta, current_depth, param)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.root.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:24:56.548224Z",
     "start_time": "2018-10-16T07:24:56.492606Z"
    }
   },
   "outputs": [],
   "source": [
    "class GBT(object):\n",
    "    def __init__(self):\n",
    "        self.params = {'gamma': 0.,\n",
    "                       'lambda': 1.,\n",
    "                       'min_split_gain': 0.1,\n",
    "                       'max_depth': 5,\n",
    "                       'learning_rate': 0.3}\n",
    "        self.best_iteration = None\n",
    "        \n",
    "    def calc_training_data_scores(self, train_set, models):\n",
    "        if len(models) == 0:\n",
    "            return None\n",
    "        X = train_set.X\n",
    "        scores = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            scores[i] = self.predict(X[i], models=models)\n",
    "        return scores\n",
    "    \n",
    "    def calc_l2_gradient(self, train_set, scores):\n",
    "        labels = train_set.y\n",
    "        hessian = np.full(len(labels), -2)\n",
    "        if scores is None:\n",
    "            grad = np.random.uniform(size=len(labels))\n",
    "        else:\n",
    "            grad = np.array([2 * (labels[i] - scores[i]) for i in range(len(labels))])\n",
    "        return grad, hessian\n",
    "    \n",
    "    def calc_l2_loss(self, models, data_set):\n",
    "        errors = []\n",
    "        X, y = data_set.X, data_set.y\n",
    "        for x, y in zip(X, y):\n",
    "            errors.append(y - self.predict(x, models))\n",
    "        return np.mean(np.square(errors))\n",
    "    \n",
    "    def build_learner(self, train_set, grad, hessian, eta):\n",
    "        learner = Tree()\n",
    "        learner.build(train_set.X, grad, hessian, eta, self.params)\n",
    "        return learner\n",
    "    \n",
    "    def train(self, params, train_set, valid_set=None, num_boost_rounds=20,\n",
    "              early_stopping_rounds=5, calc_grad=None, calc_loss=None):\n",
    "        self.params.update(params)\n",
    "        models = []\n",
    "        eta = self.params['learning_rate']\n",
    "        best_iteration = None\n",
    "        best_val_loss = np.infty\n",
    "        start = time.time()\n",
    "        \n",
    "        for cnt in range(num_boost_rounds):\n",
    "            iter_start = time.time()\n",
    "            score = self.calc_training_data_scores(train_set, models)\n",
    "            if calc_grad is None:\n",
    "                grad, hessian = self.calc_l2_gradient(train_set, score)\n",
    "            else:\n",
    "                grad, hessian = calc_grad(train_set, score)\n",
    "            learner = self.build_learner(train_set, grad, hessian, eta)\n",
    "            models.append(learner)\n",
    "            if calc_loss is None:\n",
    "                train_loss = self.calc_l2_loss(models, train_set)\n",
    "            else:\n",
    "                train_loss = calc_loss(models, train_set)\n",
    "            if valid_set is not None:\n",
    "                if calc_loss is None:\n",
    "                    val_loss = self.calc_l2_loss(models, valid_set)\n",
    "                else:\n",
    "                    val_loss = calc_loss(models, valid_set)\n",
    "            else:\n",
    "                val_loss = None\n",
    "            if val_loss is not None and val_loss <= best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_iteration = cnt\n",
    "                if cnt - best_iteration >= early_stopping_rounds:\n",
    "                    print('Early stopping, best iteration is: %d' %(best_iteration))\n",
    "                    break\n",
    "        self.models = models\n",
    "        self.best_iteration = best_iteration\n",
    "        print('Train finished. Elapsed: %.2fs, Loss: %.2f' %(time.time() - start, train_loss))\n",
    "        \n",
    "    def predict(self, x, models=None, num_iter=None):\n",
    "        if models is None:\n",
    "            models = self.models\n",
    "        return sum(m.predict(x) for m in models[:num_iter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:24:56.699612Z",
     "start_time": "2018-10-16T07:24:56.550564Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv('regression.test', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:24:56.710905Z",
     "start_time": "2018-10-16T07:24:56.702031Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = df_train[0].values\n",
    "y_test = df_test[0].values\n",
    "X_train = df_train.drop(0, axis=1).values\n",
    "X_test = df_test.drop(0, axis=1).values\n",
    "\n",
    "train_data = Dataset(X_train, y_train)\n",
    "eval_data = Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:30:22.868008Z",
     "start_time": "2018-10-16T07:24:56.713319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Train finished. Elapsed: 326.10s, Loss: 0.23\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "\n",
    "print('Start training...')\n",
    "gbt = GBT()\n",
    "gbt.train(params,\n",
    "          train_data,\n",
    "          valid_set=eval_data,\n",
    "          early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:30:22.908416Z",
     "start_time": "2018-10-16T07:30:22.870463Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for x in X_test:\n",
    "    y_pred.append(gbt.predict(x, num_iter=gbt.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:30:23.005376Z",
     "start_time": "2018-10-16T07:30:22.912917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.544"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:30:23.103037Z",
     "start_time": "2018-10-16T07:30:23.008055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5259516455147291"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:30:23.875037Z",
     "start_time": "2018-10-16T07:30:23.105474Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:30:23.881488Z",
     "start_time": "2018-10-16T07:30:23.876927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4855631253167693"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:30:23.960017Z",
     "start_time": "2018-10-16T07:30:23.883762Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pd.Series(y_pred).apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:30:24.040387Z",
     "start_time": "2018-10-16T07:30:23.962457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6081    0.3947    0.4787       228\n",
      "           1     0.6080    0.7868    0.6859       272\n",
      "\n",
      "   micro avg     0.6080    0.6080    0.6080       500\n",
      "   macro avg     0.6080    0.5908    0.5823       500\n",
      "weighted avg     0.6080    0.6080    0.5914       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(digits=4, y_pred=y_pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T07:30:24.103527Z",
     "start_time": "2018-10-16T07:30:24.042775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90 138]\n",
      " [ 58 214]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred=y_pred, y_true=y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
