{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:37.720429Z",
     "start_time": "2018-10-18T07:15:37.340838Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:37.726344Z",
     "start_time": "2018-10-18T07:15:37.723156Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:37.818301Z",
     "start_time": "2018-10-18T07:15:37.729702Z"
    }
   },
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    def __init__(self):\n",
    "        self.is_leaf = False\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.split_feature = None\n",
    "        self.split_value = None\n",
    "        self.weight = None\n",
    "\n",
    "    def _calc_gain(self, G, H, G_l, G_r, H_l, H_r, lambd, gamma):\n",
    "        \"\"\"Measure how good a tree is. Equation 7\"\"\"\n",
    "        def calc_term(g, h):\n",
    "            return np.square(g) / (h + lambd)\n",
    "        gain = 0.5 * (calc_term(G_l, H_l) +\n",
    "                      calc_term(G_r, H_r) -\n",
    "                      calc_term(G, H)) - gamma\n",
    "        # the bigger gamma, the more convative\n",
    "        return gain\n",
    "\n",
    "    def _calc_leaf_weight(self, g, h, lambd):\n",
    "        \"\"\"Calc the optimal weight of leaf node. Equation 5\"\"\"\n",
    "        return np.sum(g) / (np.sum(h) + lambd)\n",
    "    \n",
    "    def build(self, instances, grad, hessian, eta, depth, param):\n",
    "        \"\"\"Algorithm 1\"\"\"\n",
    "        if depth > param['max_depth']:\n",
    "            # If the depth now is bigger than max depth, it is leaf node, and stop growing.\n",
    "            self.is_leaf = True\n",
    "            self.weight = self._calc_leaf_weight(grad, hessian, param['lambda']) * eta\n",
    "            return\n",
    "        G = np.sum(grad)\n",
    "        H = np.sum(hessian)\n",
    "        best_gain = 0.\n",
    "        best_feature = None\n",
    "        best_val = 0.\n",
    "        best_left_instances = None\n",
    "        best_right_instances = None\n",
    "        for feature in range(instances.shape[1]):\n",
    "            G_l, H_l = 0., 0.\n",
    "            sorted_instances = instances[:, feature].argsort()\n",
    "            for j in range(sorted_instances.shape[0]):\n",
    "                G_l += grad[sorted_instances[j]]\n",
    "                H_l += hessian[sorted_instances[j]]\n",
    "                G_r = G - G_l\n",
    "                H_r = H - H_l\n",
    "                current_gain = self._calc_gain(G, H, G_l, G_r, H_l, H_r,\n",
    "                                               param['lambda'], param['gamma'])\n",
    "                if current_gain > best_gain:\n",
    "                    best_gain = current_gain\n",
    "                    best_feature = feature\n",
    "                    best_val = instances[sorted_instances[j]][feature]\n",
    "                    best_left_instances = sorted_instances[:j+1]\n",
    "                    best_right_instances = sorted_instances[j+1:]\n",
    "        if best_gain < param['min_split_gain']:\n",
    "            self.is_leaf = True\n",
    "            self.weight = self._calc_leaf_weight(grad, hessian, param['lambda']) * eta\n",
    "        else:\n",
    "            self.split_feature = best_feature\n",
    "            self.split_value = best_val\n",
    "            self.left_child = TreeNode()\n",
    "            self.left_child.build(instances[best_left_instances],\n",
    "                                  grad[best_left_instances],\n",
    "                                  hessian[best_left_instances],\n",
    "                                  eta, depth+1, param)\n",
    "\n",
    "            self.right_child = TreeNode()\n",
    "            self.right_child.build(instances[best_right_instances],\n",
    "                                   grad[best_right_instances],\n",
    "                                   hessian[best_right_instances],\n",
    "                                   eta, depth+1, param)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.weight\n",
    "        else:\n",
    "            if x[self.split_feature] <= self.split_value:\n",
    "                return self.left_child.predict(x)\n",
    "            else:\n",
    "                return self.right_child.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:37.924051Z",
     "start_time": "2018-10-18T07:15:37.820139Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    \"\"\"Tree ensemble\"\"\"\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "    \n",
    "    def build(self, instances, grad, hessian, eta, param):\n",
    "        assert len(instances) == len(grad) == len(hessian)\n",
    "        self.root = TreeNode()\n",
    "        current_depth = 0\n",
    "        self.root.build(instances, grad, hessian, eta, current_depth, param)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.root.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:37.994770Z",
     "start_time": "2018-10-18T07:15:37.926481Z"
    }
   },
   "outputs": [],
   "source": [
    "class GBT(object):\n",
    "    def __init__(self):\n",
    "        self.params = {'gamma': 0.,\n",
    "                       'lambda': 1.,\n",
    "                       'min_split_gain': 0.1,\n",
    "                       'max_depth': 5,\n",
    "                       'learning_rate': 0.3}\n",
    "        self.best_iteration = None\n",
    "        \n",
    "    def _calc_training_data_scores(self, train_set, models):\n",
    "        if len(models) == 0:\n",
    "            return None\n",
    "        X = train_set.X\n",
    "        scores = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            scores[i] = self.predict(X[i], models=models)\n",
    "        return scores\n",
    "    \n",
    "    def _calc_l2_gradient(self, train_set, scores):\n",
    "        labels = train_set.y\n",
    "        hessian = np.full(len(labels), 2)\n",
    "        if scores is None:\n",
    "            grad = np.random.uniform(size=len(labels))\n",
    "        else:\n",
    "            grad = np.array([2 * (labels[i] - scores[i]) for i in range(len(labels))])\n",
    "        return grad, hessian\n",
    "    \n",
    "    def _calc_l2_loss(self, models, data_set):\n",
    "        errors = []\n",
    "        for x, y in zip(data_set.X, data_set.y):\n",
    "            errors.append(y - self.predict(x, models))\n",
    "        return np.mean(np.square(errors))\n",
    "    \n",
    "    def _build_learner(self, train_set, grad, hessian, eta):\n",
    "        learner = Tree()\n",
    "        learner.build(train_set.X, grad, hessian, eta, self.params)\n",
    "        return learner\n",
    "    \n",
    "    def train(self, params, train_set, valid_set=None, num_boost_rounds=20,\n",
    "              early_stopping_rounds=5, calc_grad=None, calc_loss=None):\n",
    "        self.params.update(params)\n",
    "        models = []\n",
    "        eta = 1.\n",
    "        best_iteration = None\n",
    "        best_val_loss = np.infty\n",
    "        start = time.time()\n",
    "        \n",
    "        for cnt in range(num_boost_rounds):\n",
    "            iter_start = time.time()\n",
    "            scores = self._calc_training_data_scores(train_set, models)\n",
    "            if calc_grad is None:\n",
    "                grad, hessian = self._calc_l2_gradient(train_set, scores)\n",
    "            else:\n",
    "                grad, hessian = calc_grad(train_set, scores)\n",
    "            learner = self._build_learner(train_set, grad, hessian, eta)\n",
    "            if cnt > 0:\n",
    "                eta *= self.params['learning_rate']\n",
    "            models.append(learner)\n",
    "            if calc_loss is None:\n",
    "                train_loss = self._calc_l2_loss(models, train_set)\n",
    "            else:\n",
    "                train_loss = calc_loss(models, train_set)\n",
    "            if valid_set is not None:\n",
    "                if calc_loss is None:\n",
    "                    val_loss = self._calc_l2_loss(models, valid_set)\n",
    "                else:\n",
    "                    val_loss = calc_loss(models, valid_set)\n",
    "            else:\n",
    "                val_loss = None\n",
    "            if val_loss is not None and val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_iteration = cnt\n",
    "            val_loss_str = '{:.10f}'.format(val_loss) if val_loss else '-'\n",
    "            print(\"Iter {:>3}, Train's L2: {:.10f}, Valid's L2: {}, Elapsed: {:.2f} secs\"\n",
    "                  .format(cnt, train_loss, val_loss_str, time.time() - iter_start))\n",
    "            if cnt - best_iteration >= early_stopping_rounds:\n",
    "                print('Early stopping, best iteration is: %d' %(best_iteration))\n",
    "                break\n",
    "        self.models = models\n",
    "        self.best_iteration = best_iteration\n",
    "        print('Train finished. Elapsed: %.2fs, Train Loss: %.2f' %(time.time() - start, train_loss))\n",
    "        \n",
    "    def predict(self, x, models=None, num_iter=None):\n",
    "        if models is None:\n",
    "            models = self.models\n",
    "        assert models is not None\n",
    "        return np.sum([m.predict(x) for m in models[:num_iter]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:38.133630Z",
     "start_time": "2018-10-18T07:15:37.997161Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('pokemon.csv')\n",
    "data['Total'] = data['HP'] + data['Defense'] + data['Sp. Atk'] + data['Sp. Def'] + data['Speed'] + data['Attack']\n",
    "\n",
    "y_train = data.loc[:560, 'Attack'].values\n",
    "y_test = data.loc[560:, 'Attack'].values\n",
    "X_train = data.loc[:560, ['Total', 'HP', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']].values\n",
    "X_test = data.loc[560:, ['Total', 'HP', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']].values\n",
    "\n",
    "train_data = Dataset(X_train, y_train)\n",
    "eval_data = Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:40.120163Z",
     "start_time": "2018-10-18T07:15:38.136119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Iter   0, Train's L2: 7318.8400085040, Valid's L2: 7346.8219966966, Elapsed: 0.18 secs\n",
      "Iter   1, Train's L2: 27656.3761583639, Valid's L2: 27662.2996532002, Elapsed: 0.33 secs\n",
      "Iter   2, Train's L2: 46315.8277294585, Valid's L2: 46207.7928221760, Elapsed: 0.37 secs\n",
      "Iter   3, Train's L2: 54886.1256499134, Valid's L2: 54743.5371508498, Elapsed: 0.39 secs\n",
      "Iter   4, Train's L2: 57842.0827568190, Valid's L2: 57694.5557225393, Elapsed: 0.34 secs\n",
      "Iter   5, Train's L2: 58768.3695886421, Valid's L2: 58620.4679262033, Elapsed: 0.34 secs\n",
      "Early stopping, best iteration is: 0\n",
      "Train finished. Elapsed: 1.94s, Train Loss: 58768.37\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "\n",
    "print('Start training...')\n",
    "gbt = GBT()\n",
    "gbt.train(params,\n",
    "          train_data,\n",
    "          valid_set=eval_data,\n",
    "          early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:40.128301Z",
     "start_time": "2018-10-18T07:15:40.122382Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for x in X_test:\n",
    "    y_pred.append(gbt.predict(x, num_iter=gbt.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:40.200390Z",
     "start_time": "2018-10-18T07:15:40.130117Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:40.269518Z",
     "start_time": "2018-10-18T07:15:40.204822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    240.0\n",
       "mean       0.0\n",
       "std        0.0\n",
       "min        0.0\n",
       "25%        0.0\n",
       "50%        0.0\n",
       "75%        0.0\n",
       "max        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:41.041106Z",
     "start_time": "2018-10-18T07:15:40.272145Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T07:15:41.047554Z",
     "start_time": "2018-10-18T07:15:41.043179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.48045585590506"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred) ** 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
